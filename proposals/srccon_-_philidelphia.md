##How NOT to Skew with Statistics: 
####Drafing, Data Bulletproofing, + Tools for Well-*Developed* Stories

SRCON - Philadelphia - July 2014

-----

####Description: 

There's always a lot of press-stress about interactives that are misleading and skew the data they are intending to represent (see [Spurious Correlations](http://www.tylervigen.com/)). There's also a million ways that different newsrooms homebrew the bulletproofing process, and plan for how to present information with maximum integrity (see [Propublica's Guide](https://github.com/propublica/guides/blob/master/data-bulletproofing.md)). How do modern news orgs navigate deceptive data and manage to provide critical readings of complicated information? How do they develop an intuitive visual vocabulary and match it with a compelling narrative? Who's job is it to fact check, or is it everyone's responsibility and if so how is that managed?

This will be a session about ways that statistics can be charted and plotted and how to make sure that we bulletproof our data appropriately for interactive projects, as well as a way to talk through process models that we might adopt to make fact-checking and peer review an open and organization-agnostic process. Likewise, distributed newsrooms, remote work, and investigative journalism can upset a traditional data bulletproofing workflow by separating collaborators, so how is a coordinated mentality maintained while negotiating distance developement? 

This session will be about sharing techniques and tools for data munging and going over some standards for representation and collaboration. Beyond citing sources and licensing intents, we'll talk about how we package information in an interactive story and the protocols for making sure that honest representation is clear and concise in the visual-verbal vocabularies we use to communicate the news.  

####Questions:

How can we best train and standardize our bulletproofing model? 
How can we foster a supportive community of journos at the service of open news? 
How might we adopt models of code sharing, narrative versioning or open peer review to this purpose?

AND MORE!!!...+++

---
####Things to consider

**Having History**  

Increasingly our applications and projects as digital authors have an archivable/queryable history. How does this affect our documentation of our process and how can we assemble tools that make optimal use of this auto-documentation.

**Peer Review + Versioning as a Service**
Peer review models are complicated in academia as in newsrooms because there is a persistent fear of being scooped. It's particularly depressing and sad to see this in the context of crisis data, where people should be prinicipalling interested in helping parties in danger or endangered.

other considerations welcome...

----
####Links:
Versioned Writing: https://groups.google.com/forum/#!forum/versioned-writing
Editorially: https://editorially.com/
Gitbooks: https://github.com/GitbookIO/gitbook/issues/220#issuecomment-42720334
DPLA resources: http://dp.la/apps
The OJ peer review: http://theoj.org/

------
####Speaker(s):
Aurelia is a [2014 Knight Mozilla Fellow](http://opennews.org/fellowships/2014meet.html) at Ushahidi and Internews Kenya. She works on data visualizations, crowdsourced crisis mapping, and training materials for open data and developer journalists. 

...

####Attendees
Have some things to contribute, tools to solicit feedback on, or just want to listen in and learn? Join us; everyone will walk away with a stack of resources and new things to try. Promise.

